{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pre-process data\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Preprocess features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "types_of_cells = 'All'\n",
    "mol_profiles = 'All'\n",
    "therapies = 'All'\n",
    "\n",
    "features = ['GlobalCellType','cycif.slide','TIM3','pSTAT1','CD45RO','CD20','CD11c','CD207','GranzymeB','CD163','CD4','CD3d','CD8a','FOXP3','PD1','CD15','PDL1_488','Ki67','Vimentin','MHCII','MHCI','ECadherin','aSMA','CD31','pTBK1','CK7','yH2AX','cPARP1',\n",
    "            'Area','Eccentricity','Roundness','CD11c.MY','CD15.MY','CD163.MP','CD207.MY','CD31.stromal','CD4.T.cells','CD68.MP','CD8.T.cells','Cancer','Other','Other.MY','Stromal','T.regs','B.cells','Other.immune',\n",
    "            'Molecular.profile2','therapy_sequence','patient']\n",
    "\n",
    "transformation = 'LOG2' \n",
    "features_to_transform = ['TIM3','pSTAT1','CD45RO','CD20','CD11c','CD207','GranzymeB','CD163','CD4','CD3d','CD8a','FOXP3','PD1','CD15','PDL1_488','Ki67','Vimentin','MHCII','MHCI','ECadherin','aSMA','CD31','pTBK1','CK7','yH2AX','cPARP1']\n",
    "\n",
    "operation = 'remove'\n",
    "features_for_outliers = features_to_scale = ['TIM3','pSTAT1','CD45RO','CD20','CD11c','CD207','GranzymeB','CD163','CD4','CD3d','CD8a','FOXP3','PD1','CD15','PDL1_488','Ki67','Vimentin','MHCII','MHCI','ECadherin','aSMA','CD31','pTBK1','CK7','yH2AX','cPARP1',\n",
    "            'Area','Eccentricity','Roundness']\n",
    "        \n",
    "# Scale data\n",
    "scaler_dict = {'MinMax': MinMaxScaler(),'Standard': StandardScaler()}\n",
    "# MinMaxScaler scales the data to be within a specific range, usually between 0 and 1\n",
    "# StandardScaler scales the data to have a mean of zero and a standard deviation of one\n",
    "scaler_type = 'Standard' # Scaling type\n",
    "scale_by = 'slide' # Define how to scale. Available options: whole, patient, slide\n",
    "\n",
    "# Variables for machine learning step\n",
    "categorical_variables = ['Molecular.profile2', 'therapy_sequence']\n",
    "\n",
    "def choose_features(df):\n",
    "        df = df.loc[:,features]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "def transform_df(df):\n",
    "\n",
    "    try:\n",
    "        if transformation == 'LOG':\n",
    "            df.loc[:, features_to_transform] = np.log(df.loc[:, features_to_transform] + 1)\n",
    "\n",
    "        elif transformation == 'LOG2':\n",
    "            df.loc[:, features_to_transform] = np.log2(df.loc[:, features_to_transform] + 1)\n",
    "            \n",
    "        elif transformation == 'BOXCOX':\n",
    "            # transform data & save lambda value\n",
    "            for feature in features_to_transform:\n",
    "                df[feature], _ = stats.boxcox(df[feature].values)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid transformation specified.\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred data transformation: {e}\", exc_info=True)\n",
    "\n",
    "    \n",
    "            \n",
    "def remove_outliers(df):\n",
    "    \n",
    "    try:\n",
    "        if operation == 'trim_by_slide':\n",
    "            slides = df['cycif.slide'].unique()\n",
    "        \n",
    "            for slide in slides:\n",
    "                # Create a mask to filter data belonging to the current slide\n",
    "                slide_mask = df['cycif.slide'] == slide\n",
    "                \n",
    "                for feature in features_for_outliers:\n",
    "                    percentiles = np.percentile(df.loc[slide_mask, feature], [1, 99])\n",
    "                    \n",
    "                    # Replace values below the 1st percentile with the 1st percentile value\n",
    "                    df.loc[slide_mask & (df[feature] < percentiles[0]), feature] = percentiles[0]\n",
    "                    # Replace values above the 99th percentile with the 99th percentile value\n",
    "                    df.loc[slide_mask & (df[feature] > percentiles[1]), feature] = percentiles[1]\n",
    "\n",
    "        elif operation == 'remove':\n",
    "\n",
    "            df_sub = df.loc[:, features_for_outliers]\n",
    "\n",
    "            # Identify outliers using the 1st (0.01) and 99th (0.99) percentiles for each feature\n",
    "            # For each data point, 'lim' will be True if the value is within the range [0.01, 0.99], otherwise False\n",
    "            lim = np.logical_and(df_sub < df_sub.quantile(0.99, numeric_only=False),\n",
    "                            df_sub > df_sub.quantile(0.01, numeric_only=False))\n",
    "\n",
    "            # Data points outside the range [0.01, 0.99] will be replaced with NaN\n",
    "            df.loc[:, features_for_outliers] = df_sub.where(lim, np.nan)\n",
    "            \n",
    "            # Drop rows with NaN in numerical columns\n",
    "            df.dropna(subset=features_for_outliers, inplace=True)\n",
    "                    \n",
    "        else: \n",
    "            raise ValueError(\"Invalid operation specified.\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred  outliers removal: {e}\", exc_info=True)\n",
    "    \n",
    "def scaler(df):\n",
    "    \n",
    "        # Get a scaler from the dictionary of supported scaler types\n",
    "        scaler = scaler_dict.get(scaler_type)\n",
    "\n",
    "        return scaler.fit_transform(df)\n",
    "\n",
    "def scaling(df):\n",
    "    \n",
    "    try:\n",
    "        if scaler_type in scaler_dict:\n",
    "            \n",
    "            if scale_by not in ['whole','patient', 'slide']:\n",
    "                raise ValueError(f\"Invalid order: {scale_by}\")\n",
    "            \n",
    "            if scale_by == 'patient':\n",
    "                patients = df['patient'].unique()\n",
    "                # Iterate through each unique patient ID and scale the specified features for each patient separately\n",
    "                for patient in patients:\n",
    "                    df.loc[df['patient'] == patient, features_to_scale] = scaler(df.loc[df['patient'] == patient, features_to_scale])\n",
    "            \n",
    "            elif scale_by == 'slide':\n",
    "                slides = df['cycif.slide'].unique()\n",
    "                # Iterate through each unique slide and scale the specified features for each slide separately\n",
    "                for slide in slides:\n",
    "                    df.loc[df['cycif.slide'] == slide, features_to_scale] = scaler(df.loc[df['cycif.slide'] == slide, features_to_scale])\n",
    "            \n",
    "            elif scale_by == 'whole':\n",
    "                # Scale the specified features on the entire DataFrame\n",
    "                df.loc[features_to_scale] = scaler(df.loc[features_to_scale])\n",
    "            \n",
    "            return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred  scaling: {e}\", exc_info=True)\n",
    "\n",
    "def choose_types_of_cells(df):\n",
    "        \n",
    "    # Remove Others and group immune and stromal cells\n",
    "    df = df[~df[\"GlobalCellType\"].isin(['Others','Other'])]\n",
    "    df[\"GlobalCellType\"] = df[\"GlobalCellType\"].replace(to_replace = ['CD8.T.cells', 'B.cells', 'T.regs', 'CD4.T.cells'], value = 'Lymphocytes')\n",
    "    df[\"GlobalCellType\"] = df[\"GlobalCellType\"].replace(to_replace = ['CD11c.MY', 'Other.MY', 'CD163.MP', 'CD207.MY', 'CD68.MP', 'CD15.MY'], value = 'Myeloids')\n",
    "    df[\"GlobalCellType\"] = df[\"GlobalCellType\"].replace(to_replace = ['CD31.stromal'], value = 'Stromal')\n",
    "    \n",
    "    try:\n",
    "        # Leave only chosen cell types in df\n",
    "        if types_of_cells == \"Non-cancer\":\n",
    "            df = df[~df[\"GlobalCellType\"].isin(['Cancer'])]\n",
    "            \n",
    "        elif types_of_cells == \"Lymphocytes-stromal\":\n",
    "            df = df[df[\"GlobalCellType\"].isin(['Lymphocytes', 'Stromal'])]\n",
    "            \n",
    "        elif types_of_cells == \"Myeloid-stromal\":\n",
    "            df = df[df[\"GlobalCellType\"].isin(['Myeloids', 'Stromal'])]\n",
    "            \n",
    "        elif types_of_cells == \"Immune\":\n",
    "            df = df[df[\"GlobalCellType\"].isin(['Myeloids', 'Lymphocytes', 'Other.immune'])]\n",
    "\n",
    "        elif types_of_cells in [\"Cancer\", \"Stromal\", \"Myeloids\"]:\n",
    "            df = df[df[\"GlobalCellType\"] == types_of_cells]\n",
    "                \n",
    "        elif types_of_cells not in [\"All\"]:\n",
    "            raise ValueError(\"Invalid cell type(s) specified.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred while choosing cell type: {e}\", exc_info=True)\n",
    "    \n",
    "    print(f\"\\nChose successfully cell types: {df['GlobalCellType'].unique()}.\")\n",
    "    \n",
    "    df[\"GlobalCellType\"] = df[\"GlobalCellType\"].replace(to_replace = ['Myeloids', 'Lymphocytes', 'Other.immune'], value = 'Immune')\n",
    "\n",
    "    cell_types = df[\"GlobalCellType\"].unique()\n",
    "\n",
    "    unique_patients = df['patient'].unique()\n",
    "    \n",
    "    # Remove patients with too few cells for each chosen cell type\n",
    "    for cell_type in cell_types:\n",
    "        # Group df by patient and get the size of each group\n",
    "        grouped_df = df[df['GlobalCellType'] == cell_type].groupby('patient').size()\n",
    "\n",
    "        # Filter patients with 100 or fewer cells and store them\n",
    "        selected_patients = grouped_df[grouped_df <= 100].index\n",
    "\n",
    "        # Remove patients with 100 and fewer cells\n",
    "        if len(selected_patients) > 0:\n",
    "            df = df[~df['patient'].isin(selected_patients)]\n",
    "\n",
    "    unique_patients = df['patient'].unique()\n",
    "    print(f\"\\nAfter thresholding number of patients: {len(unique_patients)}\")\n",
    "    \n",
    "    # Remove column GlobalCellType\n",
    "    df = df.drop(columns='GlobalCellType')\n",
    "\n",
    "    return df\n",
    "        \n",
    "def choose_mol_profiles(df):\n",
    "    \n",
    "    if mol_profiles != 'All':\n",
    "        df = df[df['Molecular.profile2'].isin(mol_profiles)]\n",
    "    else:\n",
    "        df = df[df['Molecular.profile2'].isin(['BRCAmutmet','HRD','HRP','CCNE1amp'])]\n",
    "        \n",
    "    return df\n",
    "\n",
    "def choose_therapy_sequences(df):\n",
    "    if therapies != 'All':\n",
    "        df = df[df['therapy_sequence'] == therapies]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_categorical_inputs(df):\n",
    "\n",
    "    # Encode categorical variables \n",
    "    label_encoder_dict = {}\n",
    "    for variable in categorical_variables:\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        \n",
    "        # Convert the values of the current categorical variable to strings and encode them\n",
    "        # The encoded values will replace the original values in the DataFrame\n",
    "        df[variable] = label_encoder.fit_transform(df[variable].astype('str'))\n",
    "        \n",
    "        # Save the encoding results for the current variable in 'label_encoder_dict'\n",
    "        # The dictionary will store the unique class labels and their corresponding encoded values\n",
    "        label_encoder_dict[variable] = {\n",
    "            'label_codes': label_encoder.classes_.tolist(), \n",
    "            'label_values': label_encoder.transform(label_encoder.classes_).tolist()\n",
    "        }\n",
    "        \n",
    "        print(label_encoder_dict)\n",
    "        \n",
    "    \n",
    "    return df\n",
    "\n",
    "def prep_train_test_data(df):\n",
    "\n",
    "    # To receive same number of patients independent of runs\n",
    "    np.random.seed(33)\n",
    "    \n",
    "    # Group df by Molecular profile and therapy\n",
    "    grouped = df.groupby(['Molecular.profile2', 'therapy_sequence'])\n",
    "\n",
    "    # Assign 80% of patients from each unique group of Molecular profile and therapy to training and rest to test sets\n",
    "    X_train_full = grouped.apply(lambda x: x.loc[x['patient'].isin(np.random.choice(x['patient'].unique(), size=int(0.8*len(x['patient'].unique())), replace=False))])\n",
    "    X_test_full = grouped.apply(lambda x: x.loc[x['patient'].isin(np.setdiff1d(x['patient'].unique(), X_train_full['patient']))])\n",
    "    \n",
    "    X_train_full.reset_index(drop=True, inplace=True)\n",
    "    X_test_full.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Assign target columns to y_train and y_test\n",
    "    y_train=X_train_full['Molecular.profile2']\n",
    "    y_test=X_test_full['Molecular.profile2']\n",
    "    \n",
    "    # Drop target columns\n",
    "    X_train = X_train_full.drop(columns = ['Molecular.profile2', 'patient', 'cycif.slide'])\n",
    "    X_test = X_test_full.drop(columns = ['Molecular.profile2', 'patient', 'cycif.slide'])\n",
    "    \n",
    "    return X_train_full.drop(columns = ['patient', 'cycif.slide']),X_test_full.drop(columns = ['patient', 'cycif.slide']),X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_dataset_202403.csv\")\n",
    "df['Molecular.profile2'] = df['Molecular.profile2'].replace('BRCAmut/met', 'BRCAmutmet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Other' 'BRCAmutmet' 'HRD' 'HRP' 'CCNE1amp']\n",
      "['PDS' 'IDS']\n",
      "233\n"
     ]
    }
   ],
   "source": [
    "print(df['Molecular.profile2'].unique())\n",
    "print(df['therapy_sequence'].unique())\n",
    "print(len(df['patient'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n",
      "233\n",
      "233\n",
      "233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_597480/1333281234.py:146: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"GlobalCellType\"] = df[\"GlobalCellType\"].replace(to_replace = ['CD8.T.cells', 'B.cells', 'T.regs', 'CD4.T.cells'], value = 'Lymphocytes')\n",
      "/tmp/ipykernel_597480/1333281234.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"GlobalCellType\"] = df[\"GlobalCellType\"].replace(to_replace = ['CD11c.MY', 'Other.MY', 'CD163.MP', 'CD207.MY', 'CD68.MP', 'CD15.MY'], value = 'Myeloids')\n",
      "/tmp/ipykernel_597480/1333281234.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"GlobalCellType\"] = df[\"GlobalCellType\"].replace(to_replace = ['CD31.stromal'], value = 'Stromal')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chose successfully cell types: ['Cancer' 'Stromal' 'Lymphocytes' 'Myeloids' 'Other.immune'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_597480/1333281234.py:175: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"GlobalCellType\"] = df[\"GlobalCellType\"].replace(to_replace = ['Myeloids', 'Lymphocytes', 'Other.immune'], value = 'Immune')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After thresholding number of patients: 224\n",
      "224\n",
      "157\n",
      "157\n",
      "{'Molecular.profile2': {'label_codes': ['BRCAmutmet', 'CCNE1amp', 'HRD', 'HRP'], 'label_values': [0, 1, 2, 3]}}\n",
      "{'Molecular.profile2': {'label_codes': ['BRCAmutmet', 'CCNE1amp', 'HRD', 'HRP'], 'label_values': [0, 1, 2, 3]}, 'therapy_sequence': {'label_codes': ['IDS', 'PDS'], 'label_values': [0, 1]}}\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "df = choose_features(df)\n",
    "print(len(df['patient'].unique()))\n",
    "df = transform_df(df)\n",
    "print(len(df['patient'].unique()))\n",
    "df = remove_outliers(df)\n",
    "print(len(df['patient'].unique()))\n",
    "df = scaling(df)\n",
    "print(len(df['patient'].unique()))\n",
    "df = choose_types_of_cells(df)\n",
    "print(len(df['patient'].unique()))\n",
    "df = choose_mol_profiles(df)\n",
    "print(len(df['patient'].unique()))\n",
    "df = choose_therapy_sequences(df)\n",
    "print(len(df['patient'].unique()))\n",
    "\n",
    "df = prepare_categorical_inputs(df)\n",
    "print(len(df['patient'].unique()))\n",
    "X_train_full,X_test_full,X_train,X_test,y_train,y_test = prep_train_test_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TIM3    pSTAT1    CD45RO      CD20     CD11c     CD207  GranzymeB  \\\n",
      "0  0.856119  0.444584  2.022115  3.584032  1.704338  1.265360   0.903239   \n",
      "1  1.759301  2.009022  1.929934  1.920628  2.629491  2.370827   3.202361   \n",
      "2  2.331201 -0.251148  0.229573  1.336762 -0.138185  1.880480   0.795485   \n",
      "3  1.963668 -0.040149  0.640188  1.639086  0.205153  1.789590  -0.062243   \n",
      "4  1.631058  1.235478  1.616692  1.150106  2.582299  1.903677   0.711585   \n",
      "\n",
      "      CD163       CD4      CD3d  ...  CD8.T.cells    Cancer  Other  Other.MY  \\\n",
      "0  0.392078  4.417961  2.625805  ...     0.095238  0.333333    0.0       0.0   \n",
      "1  1.085341  2.623066  2.927081  ...     0.187500  0.562500    0.0       0.0   \n",
      "2 -0.380442  0.653997  1.238564  ...     0.050000  0.550000    0.0       0.0   \n",
      "3 -0.163565  0.998075  1.086835  ...     0.055556  0.611111    0.0       0.0   \n",
      "4  0.759488  3.059049  2.155379  ...     0.117647  0.000000    0.0       0.0   \n",
      "\n",
      "   Stromal    T.regs   B.cells  Other.immune  Molecular.profile2  \\\n",
      "0      0.0  0.000000  0.285714      0.047619                   0   \n",
      "1      0.0  0.062500  0.062500      0.125000                   0   \n",
      "2      0.0  0.000000  0.100000      0.100000                   0   \n",
      "3      0.0  0.055556  0.055556      0.111111                   0   \n",
      "4      0.0  0.000000  0.000000      0.117647                   0   \n",
      "\n",
      "   therapy_sequence  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 0  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1555200, 46)\n",
      "(405232, 46)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape)\n",
    "print(X_test_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1555200, step=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1960432, 46)\n"
     ]
    }
   ],
   "source": [
    "full_df = pd.concat([X_train_full, X_test_full], ignore_index=True)\n",
    "print(full_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TIM3    pSTAT1    CD45RO      CD20     CD11c     CD207  GranzymeB  \\\n",
      "0  0.856119  0.444584  2.022115  3.584032  1.704338  1.265360   0.903239   \n",
      "1  1.759301  2.009022  1.929934  1.920628  2.629491  2.370827   3.202361   \n",
      "2  2.331201 -0.251148  0.229573  1.336762 -0.138185  1.880480   0.795485   \n",
      "3  1.963668 -0.040149  0.640188  1.639086  0.205153  1.789590  -0.062243   \n",
      "4  1.631058  1.235478  1.616692  1.150106  2.582299  1.903677   0.711585   \n",
      "\n",
      "      CD163       CD4      CD3d  ...  CD8.T.cells    Cancer  Other  Other.MY  \\\n",
      "0  0.392078  4.417961  2.625805  ...     0.095238  0.333333    0.0       0.0   \n",
      "1  1.085341  2.623066  2.927081  ...     0.187500  0.562500    0.0       0.0   \n",
      "2 -0.380442  0.653997  1.238564  ...     0.050000  0.550000    0.0       0.0   \n",
      "3 -0.163565  0.998075  1.086835  ...     0.055556  0.611111    0.0       0.0   \n",
      "4  0.759488  3.059049  2.155379  ...     0.117647  0.000000    0.0       0.0   \n",
      "\n",
      "   Stromal    T.regs   B.cells  Other.immune  Molecular.profile2  \\\n",
      "0      0.0  0.000000  0.285714      0.047619                   0   \n",
      "1      0.0  0.062500  0.062500      0.125000                   0   \n",
      "2      0.0  0.000000  0.100000      0.100000                   0   \n",
      "3      0.0  0.055556  0.055556      0.111111                   0   \n",
      "4      0.0  0.000000  0.000000      0.117647                   0   \n",
      "\n",
      "   therapy_sequence  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 0  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "print(full_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1960432, step=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up ML experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_62ca9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_62ca9_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_62ca9_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_62ca9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_62ca9_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_62ca9_row0_col1\" class=\"data row0 col1\" >3565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62ca9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_62ca9_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_62ca9_row1_col1\" class=\"data row1 col1\" >Molecular.profile2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62ca9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_62ca9_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_62ca9_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62ca9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_62ca9_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_62ca9_row3_col1\" class=\"data row3 col1\" >(1960432, 46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62ca9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_62ca9_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_62ca9_row4_col1\" class=\"data row4 col1\" >(1960432, 46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62ca9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_62ca9_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_62ca9_row5_col1\" class=\"data row5 col1\" >(1555200, 46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62ca9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_62ca9_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_62ca9_row6_col1\" class=\"data row6 col1\" >(405232, 46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62ca9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_62ca9_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_62ca9_row7_col1\" class=\"data row7 col1\" >45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7399d91689d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Init setup\n",
    "clf1 = setup(X_train_full, target='Molecular.profile2', log_experiment = 'mlflow', experiment_name = 'Choice_of_model_202403', test_data=X_test_full, index = False, preprocess=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare nine models on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_06f8b th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_06f8b_row0_col0, #T_06f8b_row1_col0, #T_06f8b_row1_col1, #T_06f8b_row1_col2, #T_06f8b_row1_col3, #T_06f8b_row1_col4, #T_06f8b_row1_col5, #T_06f8b_row1_col6, #T_06f8b_row1_col7, #T_06f8b_row2_col0, #T_06f8b_row2_col1, #T_06f8b_row2_col2, #T_06f8b_row2_col3, #T_06f8b_row2_col4, #T_06f8b_row2_col5, #T_06f8b_row2_col6, #T_06f8b_row2_col7, #T_06f8b_row3_col0, #T_06f8b_row3_col1, #T_06f8b_row3_col2, #T_06f8b_row3_col3, #T_06f8b_row3_col4, #T_06f8b_row3_col5, #T_06f8b_row3_col6, #T_06f8b_row3_col7, #T_06f8b_row4_col0, #T_06f8b_row4_col1, #T_06f8b_row4_col2, #T_06f8b_row4_col3, #T_06f8b_row4_col4, #T_06f8b_row4_col5, #T_06f8b_row4_col6, #T_06f8b_row4_col7, #T_06f8b_row5_col0, #T_06f8b_row5_col1, #T_06f8b_row5_col2, #T_06f8b_row5_col3, #T_06f8b_row5_col4, #T_06f8b_row5_col5, #T_06f8b_row5_col6, #T_06f8b_row5_col7, #T_06f8b_row6_col0, #T_06f8b_row6_col1, #T_06f8b_row6_col2, #T_06f8b_row6_col3, #T_06f8b_row6_col4, #T_06f8b_row6_col5, #T_06f8b_row6_col6, #T_06f8b_row6_col7, #T_06f8b_row7_col0, #T_06f8b_row7_col1, #T_06f8b_row7_col2, #T_06f8b_row7_col3, #T_06f8b_row7_col4, #T_06f8b_row7_col5, #T_06f8b_row7_col6, #T_06f8b_row7_col7, #T_06f8b_row8_col0, #T_06f8b_row8_col1, #T_06f8b_row8_col2, #T_06f8b_row8_col3, #T_06f8b_row8_col4, #T_06f8b_row8_col5, #T_06f8b_row8_col6, #T_06f8b_row8_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_06f8b_row0_col1, #T_06f8b_row0_col2, #T_06f8b_row0_col3, #T_06f8b_row0_col4, #T_06f8b_row0_col5, #T_06f8b_row0_col6, #T_06f8b_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_06f8b_row0_col8, #T_06f8b_row1_col8, #T_06f8b_row2_col8, #T_06f8b_row3_col8, #T_06f8b_row4_col8, #T_06f8b_row5_col8, #T_06f8b_row6_col8, #T_06f8b_row7_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_06f8b_row8_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_06f8b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_06f8b_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_06f8b_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_06f8b_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_06f8b_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_06f8b_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_06f8b_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_06f8b_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_06f8b_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_06f8b_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_06f8b_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_06f8b_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_06f8b_row0_col1\" class=\"data row0 col1\" >0.5101</td>\n",
       "      <td id=\"T_06f8b_row0_col2\" class=\"data row0 col2\" >0.6797</td>\n",
       "      <td id=\"T_06f8b_row0_col3\" class=\"data row0 col3\" >0.5101</td>\n",
       "      <td id=\"T_06f8b_row0_col4\" class=\"data row0 col4\" >0.4970</td>\n",
       "      <td id=\"T_06f8b_row0_col5\" class=\"data row0 col5\" >0.4731</td>\n",
       "      <td id=\"T_06f8b_row0_col6\" class=\"data row0 col6\" >0.2412</td>\n",
       "      <td id=\"T_06f8b_row0_col7\" class=\"data row0 col7\" >0.2567</td>\n",
       "      <td id=\"T_06f8b_row0_col8\" class=\"data row0 col8\" >80.3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06f8b_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_06f8b_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_06f8b_row1_col1\" class=\"data row1 col1\" >0.4683</td>\n",
       "      <td id=\"T_06f8b_row1_col2\" class=\"data row1 col2\" >0.6532</td>\n",
       "      <td id=\"T_06f8b_row1_col3\" class=\"data row1 col3\" >0.4683</td>\n",
       "      <td id=\"T_06f8b_row1_col4\" class=\"data row1 col4\" >0.4440</td>\n",
       "      <td id=\"T_06f8b_row1_col5\" class=\"data row1 col5\" >0.4381</td>\n",
       "      <td id=\"T_06f8b_row1_col6\" class=\"data row1 col6\" >0.1924</td>\n",
       "      <td id=\"T_06f8b_row1_col7\" class=\"data row1 col7\" >0.2002</td>\n",
       "      <td id=\"T_06f8b_row1_col8\" class=\"data row1 col8\" >659.7120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06f8b_level0_row2\" class=\"row_heading level0 row2\" >gbc</th>\n",
       "      <td id=\"T_06f8b_row2_col0\" class=\"data row2 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_06f8b_row2_col1\" class=\"data row2 col1\" >0.4629</td>\n",
       "      <td id=\"T_06f8b_row2_col2\" class=\"data row2 col2\" >0.6363</td>\n",
       "      <td id=\"T_06f8b_row2_col3\" class=\"data row2 col3\" >0.4629</td>\n",
       "      <td id=\"T_06f8b_row2_col4\" class=\"data row2 col4\" >0.4202</td>\n",
       "      <td id=\"T_06f8b_row2_col5\" class=\"data row2 col5\" >0.4108</td>\n",
       "      <td id=\"T_06f8b_row2_col6\" class=\"data row2 col6\" >0.1573</td>\n",
       "      <td id=\"T_06f8b_row2_col7\" class=\"data row2 col7\" >0.1724</td>\n",
       "      <td id=\"T_06f8b_row2_col8\" class=\"data row2 col8\" >928.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06f8b_level0_row3\" class=\"row_heading level0 row3\" >svm</th>\n",
       "      <td id=\"T_06f8b_row3_col0\" class=\"data row3 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_06f8b_row3_col1\" class=\"data row3 col1\" >0.4500</td>\n",
       "      <td id=\"T_06f8b_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n",
       "      <td id=\"T_06f8b_row3_col3\" class=\"data row3 col3\" >0.4500</td>\n",
       "      <td id=\"T_06f8b_row3_col4\" class=\"data row3 col4\" >0.3743</td>\n",
       "      <td id=\"T_06f8b_row3_col5\" class=\"data row3 col5\" >0.3592</td>\n",
       "      <td id=\"T_06f8b_row3_col6\" class=\"data row3 col6\" >0.0961</td>\n",
       "      <td id=\"T_06f8b_row3_col7\" class=\"data row3 col7\" >0.1142</td>\n",
       "      <td id=\"T_06f8b_row3_col8\" class=\"data row3 col8\" >1.8280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06f8b_level0_row4\" class=\"row_heading level0 row4\" >lr</th>\n",
       "      <td id=\"T_06f8b_row4_col0\" class=\"data row4 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_06f8b_row4_col1\" class=\"data row4 col1\" >0.4322</td>\n",
       "      <td id=\"T_06f8b_row4_col2\" class=\"data row4 col2\" >0.5797</td>\n",
       "      <td id=\"T_06f8b_row4_col3\" class=\"data row4 col3\" >0.4322</td>\n",
       "      <td id=\"T_06f8b_row4_col4\" class=\"data row4 col4\" >0.3577</td>\n",
       "      <td id=\"T_06f8b_row4_col5\" class=\"data row4 col5\" >0.3606</td>\n",
       "      <td id=\"T_06f8b_row4_col6\" class=\"data row4 col6\" >0.1035</td>\n",
       "      <td id=\"T_06f8b_row4_col7\" class=\"data row4 col7\" >0.1139</td>\n",
       "      <td id=\"T_06f8b_row4_col8\" class=\"data row4 col8\" >14.2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06f8b_level0_row5\" class=\"row_heading level0 row5\" >lda</th>\n",
       "      <td id=\"T_06f8b_row5_col0\" class=\"data row5 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_06f8b_row5_col1\" class=\"data row5 col1\" >0.4317</td>\n",
       "      <td id=\"T_06f8b_row5_col2\" class=\"data row5 col2\" >0.5843</td>\n",
       "      <td id=\"T_06f8b_row5_col3\" class=\"data row5 col3\" >0.4317</td>\n",
       "      <td id=\"T_06f8b_row5_col4\" class=\"data row5 col4\" >0.3665</td>\n",
       "      <td id=\"T_06f8b_row5_col5\" class=\"data row5 col5\" >0.3653</td>\n",
       "      <td id=\"T_06f8b_row5_col6\" class=\"data row5 col6\" >0.1088</td>\n",
       "      <td id=\"T_06f8b_row5_col7\" class=\"data row5 col7\" >0.1195</td>\n",
       "      <td id=\"T_06f8b_row5_col8\" class=\"data row5 col8\" >1.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06f8b_level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "      <td id=\"T_06f8b_row6_col0\" class=\"data row6 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_06f8b_row6_col1\" class=\"data row6 col1\" >0.4227</td>\n",
       "      <td id=\"T_06f8b_row6_col2\" class=\"data row6 col2\" >0.5961</td>\n",
       "      <td id=\"T_06f8b_row6_col3\" class=\"data row6 col3\" >0.4227</td>\n",
       "      <td id=\"T_06f8b_row6_col4\" class=\"data row6 col4\" >0.3905</td>\n",
       "      <td id=\"T_06f8b_row6_col5\" class=\"data row6 col5\" >0.3818</td>\n",
       "      <td id=\"T_06f8b_row6_col6\" class=\"data row6 col6\" >0.1102</td>\n",
       "      <td id=\"T_06f8b_row6_col7\" class=\"data row6 col7\" >0.1185</td>\n",
       "      <td id=\"T_06f8b_row6_col8\" class=\"data row6 col8\" >44.2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06f8b_level0_row7\" class=\"row_heading level0 row7\" >dt</th>\n",
       "      <td id=\"T_06f8b_row7_col0\" class=\"data row7 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_06f8b_row7_col1\" class=\"data row7 col1\" >0.3994</td>\n",
       "      <td id=\"T_06f8b_row7_col2\" class=\"data row7 col2\" >0.5742</td>\n",
       "      <td id=\"T_06f8b_row7_col3\" class=\"data row7 col3\" >0.3994</td>\n",
       "      <td id=\"T_06f8b_row7_col4\" class=\"data row7 col4\" >0.4063</td>\n",
       "      <td id=\"T_06f8b_row7_col5\" class=\"data row7 col5\" >0.3994</td>\n",
       "      <td id=\"T_06f8b_row7_col6\" class=\"data row7 col6\" >0.1463</td>\n",
       "      <td id=\"T_06f8b_row7_col7\" class=\"data row7 col7\" >0.1473</td>\n",
       "      <td id=\"T_06f8b_row7_col8\" class=\"data row7 col8\" >12.7990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06f8b_level0_row8\" class=\"row_heading level0 row8\" >nb</th>\n",
       "      <td id=\"T_06f8b_row8_col0\" class=\"data row8 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_06f8b_row8_col1\" class=\"data row8 col1\" >0.3158</td>\n",
       "      <td id=\"T_06f8b_row8_col2\" class=\"data row8 col2\" >0.5858</td>\n",
       "      <td id=\"T_06f8b_row8_col3\" class=\"data row8 col3\" >0.3158</td>\n",
       "      <td id=\"T_06f8b_row8_col4\" class=\"data row8 col4\" >0.3923</td>\n",
       "      <td id=\"T_06f8b_row8_col5\" class=\"data row8 col5\" >0.3114</td>\n",
       "      <td id=\"T_06f8b_row8_col6\" class=\"data row8 col6\" >0.0845</td>\n",
       "      <td id=\"T_06f8b_row8_col7\" class=\"data row8 col7\" >0.0925</td>\n",
       "      <td id=\"T_06f8b_row8_col8\" class=\"data row8 col8\" >0.4550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7399d938ad50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = compare_models(include = ['lr','nb','dt','svm','rf','ada','gbc','lightgbm','lda'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nki-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
